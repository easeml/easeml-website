
- abstract: |
    We introduce CGA, a conditional VAE architecture, to control, generate, and augment text. CGA is able to
    generate natural English sentences controlling multiple semantic and syntactic attributes by combining 
    adversarial learning with a context-aware loss and a cyclical word dropout routine. We demonstrate the value 
    of the individual model components in an ablation study. The scalability of our approach is ensured through a 
    single discriminator, independently of the number of attributes. We show high quality, diversity and attribute 
    control in the generated sentences through a series of automatic and human assessments. As the main application 
    of our work, we test the potential of this new NLG model in a data augmentation scenario. In a downstream NLP 
    task, the sentences generated by our CGA model show significant improvements over a strong baseline, and a 
    classification performance often comparable to adding same amount of additional real data.
  authors:
  - G Russo
  - N Hollenstein
  - C Musat
  - C Zhang
  bibTeX: "@inproceedings{russo2020control,
    \ title={Control, Generate, Augment: A Scalable Framework for Multi-Attribute Text Generation},
    \ author={Russo, Giuseppe and Hollenstein, Nora and Musat, Claudiu Cristian and Zhang, Ce},
    \ booktitle={EMNLP (Findings)},
    \ year={2020}}"
  entryType: inproceedings
  firstPage: 1
  id: russo2020control
  links:
    paper: https://aclanthology.org/2020.findings-emnlp.33.pdf
  thumbnail: /images/papers/russo2020control.png
  title: 'Control, Generate, Augment: A Scalable Framework for Multi-​Attribute Text Generation'
  type: publication
  venueLong: Findings of the Association for Computational Linguistics
  venueShort: EMNLP
  venueTrack: null
  year: 2020
  tag: datamagic
- abstract: |
    Translating renderings (e. g. PDFs, scans) into hierarchical document structures is extensively demanded 
    in the daily routines of many real-world applications. However, a holistic, principled approach to inferring 
    the complete hierarchical structure of documents is missing. As a remedy, we developed "DocParser": an end-to-end 
    system for parsing the complete document structure - including all text elements, nested figures, tables, and 
    table cell structures. Our second contribution is to provide a dataset for evaluating hierarchical document 
    structure parsing. Our third contribution is to propose a scalable learning framework for settings where 
    domain-specific data are scarce, which we address by a novel approach to weak supervision that significantly 
    improves the document structure parsing performance. Our experiments confirm the effectiveness of our proposed 
    weak supervision: Compared to the baseline without weak supervision, it improves the mean average precision 
    for detecting document entities by 39.1 % and improves the F1 score of classifying hierarchical relations 
    by 35.8 %.
  authors:
  - J Rausch
  - O Martinez
  - F Bissig
  - C Zhang
  - S Feuerriegel
  bibTeX: "@article{rausch2019docparser,
    title={Docparser: Hierarchical structure parsing of document renderings},
    author={Rausch, Johannes and Martinez, Octavio and Bissig, Fabian and Zhang, Ce and Feuerriegel, Stefan},
    journal={arXiv preprint arXiv:1911.01702},
    year={2019}
    }"
  entryType: inproceedings
  firstPage: 1
  id: rausch2019docparser
  links:
    paper: https://arxiv.org/pdf/1911.01702.pdf
  thumbnail: /images/papers/rausch2019docparser.png
  title: "Docparser: Hierarchical structure parsing of document renderings"
  type: publication
  venueLong: Proceedings of the AAAI Conference on Artificial Intelligence
  venueShort: AAAI
  venueTrack: null
  year: 2020
  tag: datamagic
- abstract: |
    In our experience of working with domain experts who are using today's AutoML systems, a common problem 
    we encountered is what we call "unrealistic expectations" -- when users are facing a very challenging 
    task with noisy data acquisition process, whilst being expected to achieve startlingly high accuracy with 
    machine learning (ML). Consequently, many computationally expensive AutoML runs and labour-intensive ML 
    development processes are predestined to fail from the beginning. In traditional software engineering, 
    this problem is addressed via a feasibility study, an indispensable step before developing any software 
    system. In this paper, we present ease.ml/snoopy with the goal of preforming an automatic feasibility 
    study before building ML applications or collecting too many samples. A user provides inputs in the form 
    of a dataset, which is representative for the task and data acquisition process, and a quality target 
    (e.g., expected accuracy > 0.8). The system returns its deduction on whether this target is achievable 
    using ML given the input data. We approach this problem by estimating the irreducible error of the underlying 
    task, also known as Bayes error. The technical key contribution of this work is the design of a practical 
    Bayes error estimator. We carefully evaluate the benefits and limitations of running ease.ml/snoopy prior 
    to training ML models on too noisy datasets for reaching the desired target accuracy. By including the 
    automatic feasibility study into the iterative label cleaning process, users are able to save substantial 
    labeling time and monetary efforts.
  authors:
  - C Renggli
  - L Rimanić
  - L Kolar
  - N Hollenstein
  - W Wu
  - C Zhang
  bibTeX: "@article{renggli2020ease,
    title={Ease.ml/snoopy: Towards Automatic Feasibility Study for Machine Learning Applications},
    author={Renggli, Cedric and Rimanic, Luka and Kolar, Luka and Hollenstein, Nora and Wu, Wentao and Zhang, Ce},
    journal={arXiv preprint arXiv:2010.08410},
    year={2020}
    }"
  entryType: inproceedings
  firstPage: 1
  id: renggli2020ease
  links:
    paper: https://arxiv.org/pdf/2010.08410.pdf
  thumbnail: /images/papers/renggli2020ease.png
  title: "Ease.ml/snoopy: Towards Automatic Feasibility Study for Machine Learning Applications"
  type: publication
  venueLong: arXiv preprint arXiv:2010.08410
  venueShort: arXiv
  venueTrack: null
  year: 2020
  tag: snoopy
- abstract: |
    The k-Nearest Neighbors (kNN) classifier is a fundamental non-parametric machine
    learning algorithm. However, it is well known that it suffers from the curse of
    dimensionality, which is why in practice one often applies a kNN classifier on top
    of a (pre-trained) feature transformation. From a theoretical perspective, most, if
    not all theoretical results aimed at understanding the kNN classifier are derived
    for the raw feature space. This leads to an emerging gap between our theoretical
    understanding of kNN and its practical applications.

    In this paper, we take a first step towards bridging this gap. We provide a novel
    analysis on the convergence rates of a kNN classifier over transformed features.
    This analysis requires in-depth understanding of the properties that connect both
    the transformed space and the raw feature space. More precisely, we build our
    convergence bound upon two key properties of the transformed space: (1) safety
    – how well can one recover the raw posterior from the transformed space, and
    (2) smoothness – how complex this recovery function is. Based on our result, we
    are able to explain why some (pre-trained) feature transformations are better suited
    for a kNN classifier than others. We empirically validate that both properties have
    an impact on the kNN convergence on 30 feature transformations with 6 benchmark
    datasets spanning from the vision to the text domain.
  authors:
  - L Rimanić
  - C Renggli
  - B Li
  - C Zhang
  bibTeX: "@article{rimanic2020convergence,
    title={On Convergence of Nearest Neighbor Classifiers over Feature Transformations},
    author={Rimanic, Luka and Renggli, Cedric and Li, Bo and Zhang, Ce},
    journal={Advances in Neural Information Processing Systems},
    volume={33},
    year={2020}
    }"
  entryType: inproceedings
  firstPage: 1
  id: rimanic2020convergence
  links:
    paper: https://proceedings.neurips.cc/paper/2020/file/93d9033636450402d67cd55e60b3f926-Paper.pdf
  thumbnail: /images/papers/rimanic2020convergence.png
  title: On Convergence of Nearest Neighbor Classifiers over Feature Transformations
  type: publication
  venueLong: Advances in Neural Information Processing Systems
  venueShort: NeurIPS
  venueTrack: null
  year: 2020
  tag: snoopy
- abstract: |
    We demonstrate ease.ml/snoopy, a data analytics system that performs feasibility analysis for 
    machine learning (ML) applications before they are developed. Given a performance target of an ML application 
    (e.g., accuracy above 0.95), ease.ml/snoopy provides a decisive answer to ML developers regarding whether the 
    target is achievable or not. We formulate the feasibility analysis problem as an instance of Bayes error 
    estimation. That is, for a data (distribution) on which the ML application should be performed, ease.ml/snoopy 
    provides an estimate of the Bayes error - the minimum error rate that can be achieved by any classifier. It is 
    well-known that estimating the Bayes error is a notoriously hard task. In ease.ml/snoopy we explore and 
    employ estimators based on the combination of (1) nearest neighbor (NN) classifiers and (2) pre-trained 
    feature transformations. To the best of our knowledge, this is the first work on Bayes error estimation 
    that combines (1) and (2). In today's cost-driven business world, feasibility of an ML project is an ideal 
    piece of information for ML application developers - ease.ml/snoopy plays the role of a reliable "consultant."
  authors:
  - C Renggli
  - L Rimanić
  - L Kolar
  - W Wu
  - C Zhang
  bibTeX: "@article{renggli2020ease,
    title={Ease.ml/snoopy in action: Towards automatic feasibility analysis for machine learning application development},
    author={Renggli, Cedric and Rimanic, Luka and Kolar, Luka and Wu, Wentao and Zhang, Ce},
    journal={Proceedings of the VLDB Endowment},
    volume={13},
    number={12},
    pages={2837--2840},
    year={2020},
    publisher={VLDB Endowment}
    }"
  entryType: inproceedings
  firstPage: 1
  id: renggli2020ease
  links:
    Demo Video: https://www.youtube.com/watch?v=HQ0E1j35pU4
    paper: https://dl.acm.org/doi/pdf/10.14778/3415478.3415488
  thumbnail: /images/papers/renggli2020ease.png
  title: "Ease.ml/snoopy in action: Towards automatic feasibility analysis for machine learning application development"
  type: publication
  venueLong: Proceedings of the VLDB Endowment
  venueShort: VLDB
  venueTrack: Demo
  year: 2020
  tag: snoopy
- abstract: |
    The Bayes error rate (BER) is a fundamental concept in machine learning that quantifies 
    the best possible accuracy any classifier can achieve on a fixed probability distribution. 
    Despite years of research on building estimators of lower and upper bounds for the BER, 
    these were usually compared only on synthetic datasets with known probability distributions, 
    leaving two key questions unanswered: (1) How well do they perform on realistic, non-synthetic 
    datasets?, and (2) How practical are they? Answering these is not trivial. Apart from the obvious 
    challenge of an unknown BER for real-world datasets, there are two main aspects any BER estimator 
    needs to overcome in order to be applicable in real-world settings: (1) the computational and 
    sample complexity, and (2) the sensitivity and selection of hyper-parameters.In this work, 
    we propose FeeBee, the first principled framework for analyzing and comparing BER estimators 
    on modern real-world datasets with unknown probability distribution. We achieve this by injecting 
    a controlled amount of label noise and performing multiple evaluations on a series of different 
    noise levels, supported by a theoretical result which allows drawing conclusions about the evolution 
    of the BER. By implementing and analyzing 7 multi-class BER estimators on 6 commonly used 
    datasets of the computer vision and NLP domains, FeeBee allows a thorough study of these estimators, 
    clearly identifying strengths and weaknesses of each, whilst being easily deployable on any future BER estimator.
  authors:
  - C Renggli
  - L Rimanić
  - N Hollenstein
  - C Zhang
  bibTeX: "@article{renggli2021evaluating,
    title={Evaluating Bayes Error Estimators on Real-World Datasets with FeeBee},
    author={Renggli, Cedric and Rimanic, Luka and Li, Bo and Zhang, Ce},
    journal={Advances in Neural Information Processing Systems},
    volume={34},
    year={2021}
    }"
  entryType: inproceedings
  firstPage: 1
  id: renggli2021evaluating
  links:
    paper: https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/045117b0e0a11a242b9765e79cbf113f-Paper-round2.pdf
  thumbnail: /images/papers/renggli2021evaluating.png
  title: Evaluating Bayes Error Estimators on Real-World Datasets with FeeBee
  type: publication
  venueLong: Advances in Neural Information Processing Systems
  venueShort: NeurIPS
  venueTrack: Datasets and Benchmarks
  year: 2021
  tag: snoopy
- abstract: 'Machine learning (ML) applications have been thriving recently, largely
    attributed to the increasing  availability of data. However, inconsistency and
    incomplete information are ubiquitous in real-world datasets,  and their impact
    on ML applications remains elusive. In this paper, we present a formal study of
    this impact by  extending the notion of Certain Answers for Codd tables, which
    has been explored by the database research community  for decades, into the field
    of machine learning. Specifically, we focus on classification problems and propose
    the  notion of "Certain Predictions" (CP) --- a test data example can be certainly
    predicted (CP''ed) if all possible  classifiers trained on top of all possible
    worlds induced by the incompleteness of data would yield the same  prediction.
    We study two fundamental CP queries: (Q1) checking query that determines whether
    a data example can  be CP''ed; and (Q2) counting query that computes the number
    of classifiers that support a particular prediction  (i.e., label). Given that
    general solutions to CP queries are, not surprisingly, hard without assumption
    over the  type of classifier, we further present a case study in the context of
    nearest neighbor (NN) classifiers, where  efficient solutions to CP queries can
    be developed --- we show that it is possible to answer both queries in  linear
    or polynomial time over exponentially many possible worlds. We demonstrate one
    example use case of CP in  the important application of "data cleaning for machine
    learning (DC for ML)." We show that our proposed CPClean  approach built based
    on CP can often significantly outperform existing techniques, particularly on
    datasets with  systematic missing values. For example, on 5 datasets with systematic
    missingness, CPClean (with early termination)  closes 100% gap on average by cleaning
    36% of dirty data on average, while the best automatic cleaning approach  BoostClean
    can only close 14% gap on average.'
  authors:
  - B Karlaš
  - P Li
  - R Wu
  - NM Gürel
  - X Chu
  - W Wu
  - C Zhang
  bibTeX: "@article{karlas2020vldb,\n author = {Bojan Karlaš and Peng Li and Renzhi\
    \ Wu and Nezihe Merve Gürel and Xu Chu and Wentao Wu and Ce Zhang},\n journal\
    \ = {Proceedings of the VLDB Endowment},\n title = {Nearest neighbor classifiers\
    \ over incomplete information: From certain answers to certain predictions},\n\
    \ year = {2020}\n}\n\n"
  entryType: article
  firstPage: 1
  id: karlas2020vldb
  links:
    Talk Video: https://youtu.be/VsW_eZTaQD4
    paper: http://vldb.org/pvldb/vol14/p255-karlas.pdf
  thumbnail: /images/papers/karlas2020vldb.png
  title: 'Nearest neighbor classifiers over incomplete information: From certain answers
    to certain predictions'
  type: publication
  venueLong: Proceedings of the VLDB Endowment
  venueShort: VLDB
  venueTrack: null
  year: 2020
  tag: cpclean
- abstract: |
    Data quality affects machine learning (ML) model performances, and data scientists spend considerable 
    amount of time on data cleaning before model training. However, to date, there does not exist a rigorous 
    study on how exactly cleaning affects ML - ML community usually focuses on developing ML algorithms that 
    are robust to some particular noise types of certain distributions, while database (DB) community has been 
    mostly studying the problem of data cleaning alone without considering how data is consumed by downstream 
    ML analytics.We propose a CleanML study that systematically investigates the impact of data cleaning on ML 
    classification tasks. The open-source and extensible CleanML study currently includes 14 real-world datasets 
    with real errors, five common error types, seven different ML models, and multiple cleaning algorithms 
    for each error type (including both commonly used algorithms in practice as well as state-of-the-art 
    solutions in academic literature). We control the randomness in ML experiments using statistical hypothesis 
    testing, and we also control false discovery rate in our experiments using the Benjamini-Yekutieli (BY) 
    procedure. We analyze the results in a systematic way to derive many interesting and nontrivial observations. 
    We also put forward multiple research directions for researchers.
  authors:
  - P Li
  - X Rao
  - J Blase
  - Y Zhang
  - X Chu
  - C Zhang
  bibTeX: "@inproceedings{li2021cleanml,
    title={CleanML: a study for evaluating the impact of data cleaning on ml classification tasks},
    author={Li, Peng and Rao, Xi and Blase, Jennifer and Zhang, Yue and Chu, Xu and Zhang, Ce},
    booktitle={2021 IEEE 37th International Conference on Data Engineering (ICDE)},
    pages={13--24},
    year={2021},
    organization={IEEE}
    }"
  entryType: inproceedings
  firstPage: 1
  id: li2021cleanml
  links:
    paper: https://cpn-us-w2.wpmucdn.com/sites.gatech.edu/dist/b/1653/files/2021/02/CleanML_ICDE2021.pdf
  thumbnail: /images/papers/li2021cleanml.png
  title: "CleanML: a study for evaluating the impact of data cleaning on ml classification tasks"
  type: publication
  venueLong: IEEE International Conference on Data Engineering
  venueShort: ICDE
  venueTrack: null
  year: 2020
  tag: cpclean
- abstract: |
    "How much is my data worth?" is an increasingly common question posed by organizations and individuals alike. 
    An answer to this question could allow, for instance, fairly distributing profits among multiple data 
    contributors and determining prospective compensation when data breaches happen. In this paper, we study 
    the problem of data valuation by utilizing the Shapley value, a popular notion of value which originated 
    in coopoerative game theory. The Shapley value defines a unique payoff scheme that satisfies many desiderata 
    for the notion of data value. However, the Shapley value often requires exponential time to compute. 
    To meet this challenge, we propose a repertoire of efficient algorithms for approximating the Shapley value. 
    We also demonstrate the value of each training instance for various benchmark datasets.
  authors:
  - R Jia R
  - D Dao
  - B Wang
  - FA Hubis
  - N Hynes
  - NM Gürel NM
  - B Li
  - C Zhang
  - D Song
  - CJ Spanos
  bibTeX: "@inproceedings{jia2019towards,
    title={Towards efficient data valuation based on the shapley value},
    author={Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Hynes, Nick and G{\"u}rel, Nezihe Merve and Li, Bo and Zhang, Ce and Song, Dawn and Spanos, Costas J},
    booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
    pages={1167--1176},
    year={2019},
    organization={PMLR}
    }"
  entryType: inproceedings
  firstPage: 1
  id: jia2019towards
  links:
    paper: http://proceedings.mlr.press/v89/jia19a/jia19a.pdf
  thumbnail: /images/papers/jia2019towards.png
  title: Towards efficient data valuation based on the shapley value
  type: publication
  venueLong: International Conference on Artificial Intelligence and Statistics
  venueShort: AISTATS
  venueTrack: null
  year: 2019
  tag: datascope
- abstract: |
    Given a data set D containing millions of data points and a data consumer who is willing to pay for X to train
    a machine learning (ML) model over D, how should we distribute this $X to each data point to reflect its "value"? 
    In this paper, we define the "relative value of data" via the Shapley value, as it uniquely possesses 
    properties with appealing real-world interpretations, such as fairness, rationality and decentralizability. 
    For general, bounded utility functions, the Shapley value is known to be challenging to compute: to get Shapley 
    values for all N data points, it requires O(2N) model evaluations for exact computation and O(N log N) for 
    (ϵ, δ)-approximation.

    In this paper, we focus on one popular family of ML models relying on K-nearest neighbors (KNN). 
    The most surprising result is that for unweighted KNN classifiers and regressors, the Shapley value 
    of all N data points can be computed, exactly, in O(N log N) time - an exponential improvement on 
    computational complexity! Moreover, for (ϵ, δ)-approximation, we are able to develop an algorithm based 
    on Locality Sensitive Hashing (LSH) with only sublinear complexity O(Nh(ϵ, K) log N) when ϵ is not too 
    small and K is not too large. We empirically evaluate our algorithms on up to 10 million data points and 
    even our exact algorithm is up to three orders of magnitude faster than the baseline approximation algorithm. 
    The LSH-based approximation algorithm can accelerate the value calculation process even further.

    We then extend our algorithm to other scenarios such as (1) weighed KNN classifiers, (2) different data 
    points are clustered by different data curators, and (3) there are data analysts providing computation 
    who also requires proper valuation. Some of these extensions, although also being improved exponentially, 
    are less practical for exact computation (e.g., O(NK) complexity for weigthed KNN). We thus propose an 
    Monte Carlo approximation algorithm, which is O(N(log N)2/(log K)2) times more efficient than the baseline 
    approximation algorithm.
  authors:
  - R Jia
  - D Dao
  - B Wang
  - FA Hubis
  - NM Gürel
  - B Li
  - C Zhang
  - CJ Spanos
  - D Song
  bibTeX: "@article{jia12efficient,
    title={Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms},
    author={Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Gurel, Nezihe Merve and Zhang, Bo Li4 Ce and Song, Costas Spanos1 Dawn},
    journal={Proceedings of the VLDB Endowment},
    volume={12},
    year={2019},
    number={11}
    }"
  entryType: inproceedings
  firstPage: 1
  id: jia12efficient
  links:
    paper: http://www.vldb.org/pvldb/vol12/p1610-jia.pdf
  thumbnail: /images/papers/jia12efficient.png
  title: Efficient task-specific data valuation for nearest neighbor algorithms
  type: publication
  venueLong: Proceedings of the VLDB Endowment
  venueShort: VLDB
  venueTrack: null
  year: 2019
  tag: datascope
- abstract: |
    Quantifying the importance of each training point to a learning task is a fundamental problem in machine 
    learning and the estimated importance scores have been leveraged to guide a range of data workflows such 
    as data summarization and domain adaption. One simple idea is to use the leave-one-out error of each 
    training point to indicate its importance. Recent work has also proposed to use the Shapley value, as it 
    defines a unique value distribution scheme that satisfies a set of appealing properties. However, calculating 
    Shapley values is often expensive, which limits its applicability in real-world applications at scale. 
    Multiple heuristics to improve the scalability of calculating Shapley values have been proposed recently, 
    with the potential risk of compromising their utility in real-world applications.

    How well do existing data quantification methods perform on existing workflows? How do these methods 
    compare with each other, empirically and theoretically? Must we sacrifice scalability for the utility 
    in these workflows when using these methods? In this paper, we conduct a novel theoretical analysis 
    comparing the utility of different importance quantification methods, and report extensive experimental 
    studies on existing and proposed workflows such as noisy label detection, watermark removal, data summarization, 
    data acquisition, and domain adaptation. We show that Shapley value approximation based on a KNN surrogate 
    over pre-trained feature embeddings obtains comparable utility with existing algorithms while achieving 
    significant scalability improvement, often by orders of magnitude. Our theoretical analysis also justifies 
    its advantage over the leave-one-out error.
  authors:
  - R Jia
  - X Sun
  - J Xu
  - C Zhang
  - B Li
  - D Song
  bibTeX: "@article{jia2019empirical,
    title={An empirical and comparative analysis of data valuation with scalable algorithms},
    author={Jia, Ruoxi and Sun, Xuehui and Xu, Jiacen and Zhang, Ce and Li, Bo and Song, Dawn},
    journal={arXiv preprint arXiv:1911.07128},
    year={2019}
    }"
  entryType: inproceedings
  firstPage: 1
  id: jia2019empirical
  links:
    paper: https://arxiv.org/pdf/1911.07128.pdf
  thumbnail: /images/papers/jia2019empirical.png
  title: An empirical and comparative analysis of data valuation with scalable algorithms
  type: publication
  venueLong: Conference on Computer Vision and Pattern Recognition
  venueShort: CVPR
  venueTrack: null
  year: 2021
  tag: datascope
- abstract: |
    We present ease.ml, a declarative machine learning service platform. With ease.ml, a user defines the 
    high-level schema of an ML application and submits the task via a Web interface. The system then deals with 
    the rest, such as model selection and data movement. The ultimate question we hope to understand is that, 
    as a "service provider" that manages a shared cluster of machines running machine learning workloads, what 
    is the resource sharing strategy that maximizes the global satisfaction of all our users?

    This paper does not completely answer this general question, but focuses on solving the first 
    technical challenge we were facing when trying to build ease.ml. We observe that resource sharing is a 
    critical yet subtle issue in this multi-tenant scenario, as we have to balance between efficiency and 
    fairness. We first formalize the problem that we call multi-tenant model selection, aiming for minimizing 
    the total regret of all users running automatic model selection tasks. We then develop a novel algorithm 
    that combines multi-armed bandits with Bayesian optimization and prove a regret bound under the 
    multi-tenant setting. Finally, we report our evaluation of ease.ml on synthetic data and on two 
    services we are providing to our users, namely, image classification with deep neural networks and 
    binary classification with Azure ML Studio. Our experimental evaluation results show that our proposed 
    solution can be up to 9.8x faster in achieving the same global average accuracy for all users as the 
    two popular heuristics used by our users before ease.ml, and 4.1 x faster than state-of-the-art systems.
  authors:
  - T Li
  - J Zhong
  - J Liu
  - W Wu
  - C Zhang
  bibTeX: "@article{li2018ease,
    title={Ease.ml: Towards multi-tenant resource sharing for machine learning workloads},
    author={Li, Tian and Zhong, Jie and Liu, Ji and Wu, Wentao and Zhang, Ce},
    journal={Proceedings of the VLDB Endowment},
    volume={11},
    number={5},
    pages={607--620},
    year={2018},
    publisher={VLDB Endowment}
    }"
  entryType: inproceedings
  firstPage: 1
  id: li2018ease
  links:
    paper: http://www.vldb.org/pvldb/vol11/p607-li.pdf
  thumbnail: /images/papers/li2018ease.png
  title: "Ease.ml: Towards multi-tenant resource sharing for machine learning workloads"
  type: publication
  venueLong: Proceedings of the VLDB Endowment
  venueShort: VLDB
  venueTrack: null
  year: 2018
  tag: automl
- abstract: 'We demonstrate ease.ml, a multi-tenant machine learning service we host
    at ETH Zurich for various research groups. Unlike existing machine learning services,
    ease.ml presents a novel architecture that supports multi-tenant, cost-aware model
    selection that optimizes for minimizing total regrets of all users. Moreover,
    it provides a novel user interface that enables declarative machine learning at
    a higher level: Users only need to specify the input/output schemata of their
    learning tasks and ease.ml can handle the rest. In this demonstration, we present
    the design principles of ease.ml, highlight the implementation of its key components,
    and showcase how ease.ml can help ease machine learning tasks that often perplex
    even experienced users.'
  authors:
  - B Karlaš
  - J Liu
  - W Wu
  - C Zhang
  bibTeX: "@article{karlas2018vldb,\n author = {Bojan Karlaš and Ji Liu and Wentao\
    \ Wu and Ce Zhang},\n journal = {Proceedings of the VLDB Endowment},\n title =\
    \ {ease.ml in action: towards multi-tenant declarative learning services},\n year\
    \ = {2018}\n}\n\n"
  entryType: article
  firstPage: 1
  id: karlas2018vldb
  links:
    code: https://github.com/DS3Lab/easeml
    paper: https://dl.acm.org/doi/abs/10.14778/3229863.3236258
  thumbnail: /images/papers/karlas2018vldb.png
  title: 'ease.ml in action: towards multi-tenant declarative learning services'
  type: publication
  venueLong: Proceedings of the VLDB Endowment
  venueShort: VLDB
  venueTrack: Demo
  year: 2018
  tag: automl
- abstract: 'AutoML has become a popular service that is provided by most leading
    cloud service providers today. In this paper, we focus on the AutoML problem from
    the\emph {service provider’s perspective}, motivated by the following practical
    consideration: When an AutoML service needs to serve {\em multiple users} with
    {\em multiple devices} at the same time, how can we allocate these devices to
    users in an efficient way? We focus on GP-EI, one of the most popular algorithms
    for automatic model selection and hyperparameter tuning, used by systems such
    as Google Vizer. The technical contribution of this paper is the first multi-device,
    multi-tenant algorithm for GP-EI that is aware of\emph {multiple} computation
    devices and multiple users sharing the same set of computation devices. Theoretically,
    given  users and  devices, we obtain a regret bound of $ O ((\text {\bf {MIU}}(T,
    K)+ M)\frac {N^ 2}{M}) $, where $\text {\bf {MIU}}(T, K) $ refers to the maximal
    incremental uncertainty up to time  for the covariance matrix . Empirically, we
    evaluate our algorithm on two applications of automatic model selection, and show
    that our algorithm significantly outperforms the strategy of serving users independently.
    Moreover, when multiple computation devices are available, we achieve near-linear
    speedup when the number of users is much larger than the number of devices.'
  authors:
  - C Yu
  - B Karlaš
  - J Zhong
  - C Zhang
  - J Liu
  bibTeX: "@misc{yu2019aistats,\n author = {Chen Yu and Bojan Karlaš and Jie Zhong\
    \ and Ce Zhang and Ji Liu},\n title = {Automl from service provider’s perspective:\
    \ Multi-device, multi-tenant model selection with gp-ei},\n year = {2019}\n}\n\
    \n"
  entryType: misc
  firstPage: 1
  id: yu2019aistats
  links:
    paper: http://proceedings.mlr.press/v89/yu19e.html
  thumbnail: /images/papers/yu2019aistats.png
  title: 'Automl from service provider’s perspective: Multi-device, multi-tenant model
    selection with gp-ei'
  type: publication
  venueLong: 22nd International Conference on Artificial Intelligence and Statistics
  venueShort: AISTATS
  venueTrack: null
  year: 2019
  tag: automl
- abstract: |
    The Combined Algorithm Selection and Hyperparameter optimization (CASH) is one of the most fundamental 
    problems in Automatic Machine Learning (AutoML). The existing Bayesian optimization (BO) based solutions 
    turn the CASH problem into a Hyperparameter Optimization (HPO) problem by combining the hyperparameters 
    of all machine learning (ML) algorithms, and use BO methods to solve it. As a result, these methods 
    suffer from the low-efficiency problem due to the huge hyperparameter space in CASH. To alleviate this 
    issue, we propose the alternating optimization framework, where the HPO problem for each ML algorithm 
    and the algorithm selection problem are optimized alternately. In this framework, the BO methods are 
    used to solve the HPO problem for each ML algorithm separately, incorporating a much smaller hyperparameter 
    space for BO methods. Furthermore, we introduce Rising Bandits, a CASH-oriented Multi-Armed Bandits (MAB) 
    variant, to model the algorithm selection in CASH. This framework can take the advantages of both BO in 
    solving the HPO problem with a relatively small hyperparameter space and the MABs in accelerating the 
    algorithm selection. Moreover, we further develop an efficient online algorithm to solve the 
    Rising Bandits with provably theoretical guarantees. The extensive experiments on 30 OpenML datasets 
    demonstrate the superiority of the proposed approach over the competitive baselines.
  authors:
  - Y Li
  - J Jiang
  - J Gao
  - Y Shao
  - C Zhang
  - B Cui
  bibTeX: "@inproceedings{li2020efficient,
    title={Efficient Automatic CASH via Rising Bandits},
    author={Li, Yang and Jiang, Jiawei and Gao, Jinyang and Shao, Yingxia and Zhang, Ce and Cui, Bin},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    volume={34},
    number={04},
    pages={4763--4771},
    year={2020}
    }"
  entryType: inproceedings
  firstPage: 1
  id: li2020efficient
  links:
    paper: https://arxiv.org/pdf/2012.04371.pdf
  thumbnail: /images/papers/li2020efficient.png
  title: Efficient Automatic CASH via Rising Bandits
  type: publication
  venueLong: Proceedings of the AAAI Conference on Artificial Intelligence
  venueShort: AAAI
  venueTrack: null
  year: 2020
  tag: automl
- abstract: |
    Learning text representation is crucial for text classification and other language related tasks. 
    There are a diverse set of text representation networks in the literature, and how to find the optimal 
    one is a non-trivial problem. Recently, the emerging Neural Architecture Search (NAS) techniques have 
    demonstrated good potential to solve the problem. Nevertheless, most of the existing works of NAS focus on 
    the search algorithms and pay little attention to the search space. In this paper, we argue that the search 
    space is also an important human prior to the success of NAS in different applications. Thus, we propose a 
    novel search space tailored for text representation. Through automatic search, the discovered network 
    architecture outperforms state-of-the-art models on various public datasets on text classification and natural 
    language inference tasks. Furthermore, some of the design principles found in the automatic network agree 
    well with human intuition.
  authors:
  - Y Wang
  - Y Yang
  - Y Chen
  - J Bai
  - C Zhang
  - G Su
  - X Kou
  - Y Tong
  - M Yang
  - L Zhou
  bibTeX: "@inproceedings{wang2020textnas,
    title={TextNAS: A neural architecture search space tailored for text representation},
    author={Wang, Yujing and Yang, Yaming and Chen, Yiren and Bai, Jing and Zhang, Ce and Su, Guinan and Kou, Xiaoyu and Tong, Yunhai and Yang, Mao and Zhou, Lidong},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    volume={34},
    number={05},
    pages={9242--9249},
    year={2020}
    }"
  entryType: inproceedings
  firstPage: 1
  id: wang2020textnas
  links:
    paper: https://arxiv.org/pdf/1912.10729.pdf
  thumbnail: /images/papers/wang2020textnas.png
  title: "TextNAS: A neural architecture search space tailored for text representation"
  type: publication
  venueLong: Proceedings of the AAAI Conference on Artificial Intelligence
  venueShort: AAAI
  venueTrack: null
  year: 2020
  tag: automl
- abstract: |
    End-to-end AutoML has attracted intensive interests from both academia and industry, which automatically 
    searches for ML pipelines in a space induced by feature engineering, algorithm/model selection, and 
    hyper-parameter tuning. Existing AutoML systems, however, suffer from scalability issues when applying to 
    application domains with large, high-dimensional search spaces. We present VolcanoML, a scalable and 
    extensible framework that facilitates systematic exploration of large AutoML search spaces. VolcanoML 
    introduces and implements basic building blocks that decompose a large search space into smaller ones, 
    and allows users to utilize these building blocks to compose an execution plan for the AutoML problem at 
    hand. VolcanoML further supports a Volcano-style execution model - akin to the one supported by modern 
    database systems - to execute the plan constructed. Our evaluation demonstrates that, not only does 
    VolcanoML raise the level of expressiveness for search space decomposition in AutoML, it also leads to 
    actual findings of decomposition strategies that are significantly more efficient than the ones employed 
    by state-of-the-art AutoML systems such as auto-sklearn.
  authors:
  - Y Li
  - Y Shen
  - W Zhang
  - J Jiang
  - B Ding
  - Y Li
  - J Zhou
  - Z Yang
  - W Wu
  - C Zhang
  - B Cui
  bibTeX: "@article{li2021volcanoml,
    title={VolcanoML: speeding up end-to-end AutoML via scalable search space decomposition},
    author={Li, Yang and Shen, Yu and Zhang, Wentao and Jiang, Jiawei and Ding, Bolin and Li, Yaliang and Zhou, Jingren and Yang, Zhi and Wu, Wentao and Zhang, Ce and others},
    journal={Proceedings of the VLDB Endowment},
    volume={14},
    number={11},
    pages={2167--2176},
    year={2021},
    publisher={VLDB Endowment}
    }"
  entryType: inproceedings
  firstPage: 1
  id: li2021volcanoml
  links:
    paper: http://www.vldb.org/pvldb/vol14/p2167-li.pdf
  thumbnail: /images/papers/li2021volcanoml.png
  title: "VolcanoML: speeding up end-to-end AutoML via scalable search space decomposition"
  type: publication
  venueLong: Proceedings of the VLDB Endowment
  venueShort: VLDB
  venueTrack: null
  year: 2021
  tag: automl
- abstract: 'Continuous integration is an indispensable step of modern software engineering
    practices to systematically manage the life cycles of system development. Developing
    a machine learning model is no difference — it is an engineering process with
    a life cycle, including design, implementation, tuning, testing, and deployment.
    However, most, if not all, existing continuous integration engines do not support
    machine learning as first-class citizens.

    In this paper, we present ease.ml/ci, to our best knowledge, the first continuous
    integration system for machine learning. The challenge of building ease.ml/ci
    is to provide rigorous guarantees, e.g., single accuracy point error tolerance
    with 0.999 reliability, with a practical amount of labeling effort, e.g., 2K labels
    per test. We design a domain specific language that allows users to specify integration
    conditions with reliability constraints, and develop simple novel optimizations
    that can lower the number of labels required by up to two orders of magnitude
    for test conditions popularly used in real production systems.'
  authors:
  - C Renggli
  - B Karlaš
  - B Ding
  - F Liu
  - K Schawinski
  - W Wu
  - C Zhang
  bibTeX: "@inproceedings{renggli2019mlsys,\n author = {Cedric Renggli and Bojan Karlaš\
    \ and Bolin Ding and Feng Liu and Kevin Schawinski and Wentao Wu and Ce Zhang},\n\
    \ booktitle = {Proceedings of Machine Learning and Systems},\n title = {Continuous\
    \ Integration of Machine Learning Models with ease.ml/ci: A Rigorous Yet Practical Treatment},\n\
    \ year = {2019}\n}\n\n"
  entryType: inproceedings
  firstPage: 1
  id: renggli2019mlsys
  links:
    Talk Video: https://www.youtube.com/watch?v=yzABa3G509o
    paper: https://mlsys.org/Conferences/2019/doc/2019/162.pdf
  thumbnail: /images/papers/renggli2019mlsys.png
  title: 'Continuous Integration of Machine Learning Models with ease.ml/ci: A Rigorous Yet Practical
    Treatment'
  type: publication
  venueLong: Proceedings of Machine Learning and Systems
  venueShort: MLSYS
  venueTrack: null
  year: 2019
  tag: ci
- abstract: 'Developing machine learning (ML) applications is similar to developing
    traditional software --- it is often an iterative process in which developers
    navigate within a rich space of requirements, design decisions, implementations,
    empirical quality, and performance. In traditional software development, software
    engineering is the field of study which provides principled guidelines for this
    iterative process. However, as of today, the counterpart of "software engineering
    for ML" is largely missing --- developers of ML applications are left with powerful
    tools (e.g., TensorFlow and PyTorch) but little guidance regarding the development
    lifecycle itself.In this paper, we view the management of ML development life-cycles
    from a data management perspective. We demonstrate two closely related systems,
    ease.ml/ci and ease.ml/meter, that provide some "principled guidelines" for ML
    application development: ci is a continuous …'
  authors:
  - C Renggli
  - FA Hubis
  - B Karlaš
  - K Schawinski
  - W Wu
  - C Zhang
  bibTeX: "@article{renggli2019vldb,\n author = {Cedric Renggli and Frances Ann Hubis\
    \ and Bojan Karlaš and Kevin Schawinski and Wentao Wu and Ce Zhang},\n journal\
    \ = {Proceedings of the VLDB Endowment},\n title = {ease.ml/ci and ease.ml/meter\
    \ in action: towards data management for statistical generalization},\n year =\
    \ {2019}\n}\n\n"
  entryType: article
  firstPage: 1
  id: renggli2019vldb
  links:
    paper: http://www.vldb.org/pvldb/vol12/p1962-renggli.pdf
  thumbnail: /images/papers/renggli2019vldb.png
  title: 'ease.ml/ci and ease.ml/meter in action: towards data management for statistical
    generalization'
  type: publication
  venueLong: Proceedings of the VLDB Endowment
  venueShort: VLDB
  venueTrack: Demo
  year: 2019
  tag: ci
- abstract: Continuous integration (CI) has been a de facto standard for building
    industrial-strength software. Yet, there is little attention towards applying
    CI to the development of machine learning (ML) applications until the very recent
    effort on the theoretical side. In this paper, we take a step forward to bring
    the theory into practice.
  authors:
  - B Karlaš
  - M Interlandi
  - C Renggli
  - W Wu
  - C Zhang
  - DMI Babu
  - J Edwards
  - C Lauren
  - A Xu
  - M Weimer
  bibTeX: "@inproceedings{karlas2020sigkdd,\n author = {Bojan Karlaš and Matteo Interlandi\
    \ and Cedric Renggli and Wentao Wu and Ce Zhang and Deepak Mukunthu Iyappan Babu\
    \ and Jordan Edwards and Chris Lauren and Andy Xu and Markus Weimer},\n booktitle\
    \ = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge\
    \ Discovery & Data Mining},\n title = {Building continuous integration services\
    \ for machine learning},\n year = {2020}\n}\n\n"
  entryType: inproceedings
  firstPage: 1
  id: karlas2020sigkdd
  links:
    Promo Video: https://www.youtube.com/watch?v=m8aV1HnOnN0
    Talk Video: https://dl.acm.org/doi/abs/10.1145/3394486.3403290
    paper: https://dl.acm.org/doi/pdf/10.1145/3394486.3403290
  thumbnail: /images/papers/karlas2020sigkdd.png
  title: Building continuous integration services for machine learning
  type: publication
  venueLong: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge
    Discovery & Data Mining
  venueShort: SIGKDD
  venueTrack: null
  year: 2020
  tag: ci
- abstract: Given  pre-trained classifiers and a stream of unlabeled data examples,
    how can we actively decide when to query a label so that we can distinguish the
    best model from the rest while making a small number of queries? Answering this
    question has a profound impact on a range of practical scenarios. In this work,
    we design an online selective sampling approach that actively selects informative
    examples to label and outputs the best model with high probability at any round.
    Our algorithm can also be used for online prediction tasks for both adversarial
    and stochastic streams. We establish several theoretical guarantees for our algorithm
    and extensively demonstrate its effectiveness in our experimental studies.
  authors:
  - MR Karimi
  - NM Gürel
  - B Karlaš
  - J Rausch
  - C Zhang
  - A Krause
  bibTeX: "@inproceedings{karimi2021aistats,\n author = {Mohammad Reza Karimi and\
    \ Nezihe Merve Gürel and Bojan Karlaš and Johannes Rausch and Ce Zhang and Andreas\
    \ Krause},\n booktitle = {International Conference on Artificial Intelligence\
    \ and Statistics},\n title = {Online Active Model Selection for Pre-trained Classifiers},\n\
    \ year = {2021}\n}\n\n"
  entryType: inproceedings
  firstPage: 1
  id: karimi2021aistats
  links:
    paper: http://proceedings.mlr.press/v130/reza-karimi21a/reza-karimi21a.pdf
  thumbnail: /images/papers/karimi2021aistats.png
  title: Online Active Model Selection for Pre-trained Classifiers
  type: publication
  venueLong: International Conference on Artificial Intelligence and Statistics
  venueShort: AISTATS
  venueTrack: null
  year: 2021
  tag: modelpicker
- abstract: We present Ease.ML, a lifecycle management system for machine learning
    (ML). Unlike many existing works, which focus on improving individual steps during
    the lifecycle of ML application development, Ease.ML focuses on managing and automating
    the entire lifecycle itself. We present user scenarios that have motivated the
    development of Ease.ML, the eight-step Ease.ML process that covers the lifecycle
    of ML application development; the foundation of Ease.ML in terms of a probabilistic
    database model and its connection to information theory; and our lessons learned,
    which hopefully can inspire future research.
  authors:
  - LA Melgar
  - D Dao
  - S Gan
  - NM Gürel
  - N Hollenstein
  - J Jiang
  - B Karlaš
  - T Lemmin
  - T Li
  - Y Li
  - S Rao
  - J Rausch
  - C Renggli
  - L Rimanic
  - M Weber
  - S Zhang
  - Z Zhao
  - K Schawinski
  - W Wu
  - C Zhang
  bibTeX: "@inproceedings{melgar2021cidr,\n author = {Leonel Aguilar Melgar and David\
    \ Dao and Shaoduo Gan and Nezihe M Gürel and Nora Hollenstein and Jiawei Jiang\
    \ and Bojan Karlaš and Thomas Lemmin and Tian Li and Yang Li and Susie Rao and\
    \ Johannes Rausch and Cedric Renggli and Luka Rimanic and Maurice Weber and Shuai\
    \ Zhang and Zhikuan Zhao and Kevin Schawinski and Wentao Wu and Ce Zhang},\n booktitle\
    \ = {Conference on Innovative Data Systems Research},\n title = {Ease.ML: A Lifecycle\
    \ Management System for MLDev and MLOps},\n year = {2021}\n}\n\n"
  entryType: inproceedings
  firstPage: 1
  id: melgar2021cidr
  links:
    paper: http://cidrdb.org/cidr2021/papers/cidr2021_paper26.pdf
    video: https://www.youtube.com/watch?v=HYRngtBUFXk
  thumbnail: /images/papers/melgar2021cidr.png
  title: 'Ease.ML: A Lifecycle Management System for MLDev and MLOps'
  type: publication
  venueLong: Conference on Innovative Data Systems Research
  venueShort: CIDR
  venueTrack: null
  year: 2021
  tag: easeml
